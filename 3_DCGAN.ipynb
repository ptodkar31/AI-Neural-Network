{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Convolutional Genrative Adversarial Network"
      ],
      "metadata": {
        "id": "ftljYWawk4D5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7RrmH2VlGjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cabd991-55ef-4064-a195-cdf3a353f7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.11.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.26)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.44.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F28El_7gocZh",
        "outputId": "f69813d2-f432-4b72-dc85-aa4654830a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "jp2nWSadpMng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The left side of the assignment destructures the returned tuples from load_data(). X_train: This is the training dataset containing the images of the handwritten digits. It will be a NumPy array of shape (60000, 28, 28) where 60,000 is the number of training samples, and 28x28 is the resolution of each image. y_train: This is the training labels corresponding to X_train. It contains the digit labels (0-9) for each image, with shape (60000). (_,): This part is used to ignore the test data. The underscore () is a convention to signify that the value is being ignored. So, you're not storing X_test and y_test in this case."
      ],
      "metadata": {
        "id": "72Bae4_xp-T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdUtxYikocj7",
        "outputId": "4bd665de-15e5-471f-a35a-f96681c5a51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwF-h76hocmi",
        "outputId": "785e1052-4891-434b-b2b8-cc2f5e538512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "28 * 28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-j-z9qSocov",
        "outputId": "f38bbe9d-f4a6-449c-917d-7fadade73366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uPRiAOEocq0",
        "outputId": "5551c9d0-ab82-43e4-dd82-490fb84e08f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=np.random.randint(0,6000)\n",
        "#print(i)\n",
        "print(y_train[i])\n",
        "plt.imshow(X_train[i],cmap='gray');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "cMIcNjfIoctD",
        "outputId": "12c7a89d-cb34-4cba-9284-0499f364cee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')"
      ],
      "metadata": {
        "id": "o2x-Tddaocwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8seXDihnq7d4",
        "outputId": "024e1e4d-6854-4d68-ef96-a98f036120e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].min(),X_train[0].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI81B4Nxq7gS",
        "outputId": "97c83fc0-9cfb-4e9c-da69-4ee60541f6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 255.0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = (X_train - 127.5) / 127.5"
      ],
      "metadata": {
        "id": "Fas8njTTq7jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].min(),X_train[0].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgM6TLSMq7lu",
        "outputId": "471c9fb4-b8a5-4373-e885-4deb27a78b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size = 60000\n",
        "batch_size = 256"
      ],
      "metadata": {
        "id": "r6zyuLotq7oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size/batch_size #mini batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ew9PiYUq7qq",
        "outputId": "136664cd-d5c0-4ff7-ccd6-fb38a999e57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234.375"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RHfzS5Zq7uF",
        "outputId": "2758b970-e738-4ad6-9a52-5b28201dfc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size).batch(batch_size)"
      ],
      "metadata": {
        "id": "3n4umvmUrtxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code transforms X_train (which is typically a large dataset) into a tf.data.Dataset object, shuffles the data with a buffer size of buffer_size, and groups it into batches of size batch_size for efficient training. This is a typical preprocessing step before feeding data into a TensorFlow model."
      ],
      "metadata": {
        "id": "Ss0tqgKfsQw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "eJ9fehd2rt0E",
        "outputId": "d68ad861-31c9-4337-e478-185580190106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.batch_op._BatchDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.batch_op._BatchDataset</b><br/>def __init__(input_dataset, batch_size, drop_remainder, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/batch_op.py</a>A `Dataset` that batches contiguous elements from its input.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 50);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DkVaGFgrt2b",
        "outputId": "31a6f219-2de8-4929-966a-808e0fff5fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Generator"
      ],
      "metadata": {
        "id": "1zQCkXaFtNox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch normalization: https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
        "\n",
        "Leaky Relu: https://keras.io/api/layers/activation_layers/leaky_relu/\n",
        "\n",
        "Activation Function: https://medium.com/@himanshuxd/activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e\n",
        "\n",
        "Padding: https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow"
      ],
      "metadata": {
        "id": "vFxiD1hLvVtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " 7 * 7 * 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY4Aqu8grt42",
        "outputId": "8c8e3808-df7b-4640-f12d-f45347d3d516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12544"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 100 -> 12544\n",
        "def build_generator():\n",
        "  network = tf.keras.Sequential()\n",
        "\n",
        "  network.add(layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  network.add(layers.Reshape((7, 7, 256)))\n",
        "\n",
        "  # 7 * 7 * 128\n",
        "  network.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  # 14 * 14 * 64\n",
        "  network.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  network.add(layers.BatchNormalization())\n",
        "  network.add(layers.LeakyReLU())\n",
        "\n",
        "  # 28 * 28 * 1\n",
        "  network.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  network.summary()\n",
        "\n",
        "  return network"
      ],
      "metadata": {
        "id": "sXGRYiA1xAcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r62inH7jxAe9",
        "outputId": "b9d297e4-784e-4ee1-f2d7-f81eebadf713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12544)             1254400   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 12544)            50176     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819200    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1600      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,330,944\n",
            "Trainable params: 2,305,472\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ1aTNGXxAg6",
        "outputId": "7d552fe9-6f1e-4496-dfa8-f48db4101b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'dense_input')>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal([1, 100])\n",
        "noise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj93opS6xAi1",
        "outputId": "336b34fa-2ee7-4366-95ca-4ac4c0fd33a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
              "array([[ 2.58201901e-02,  1.66712523e+00,  6.44854963e-01,\n",
              "        -1.50575566e+00,  1.84651569e-01,  8.34921956e-01,\n",
              "         1.43164301e+00,  1.19318652e+00, -6.16485178e-01,\n",
              "        -1.36483476e-01,  1.03815854e+00,  1.17215765e+00,\n",
              "         1.63678586e+00,  1.55778108e-02,  6.63288891e-01,\n",
              "         2.81962100e-02, -2.96696454e-01,  1.06325173e+00,\n",
              "         2.06178570e+00, -5.89491487e-01, -3.36791277e-01,\n",
              "         5.01634896e-01,  1.57150492e-01, -2.09541559e+00,\n",
              "         1.70721069e-01, -3.99005502e-01,  9.28068638e-01,\n",
              "        -4.61921632e-01, -4.39062327e-01,  1.98314413e-01,\n",
              "        -4.77660477e-01,  4.58715469e-01,  4.38620389e-01,\n",
              "         1.39519358e+00,  1.01334405e+00,  3.63803446e-01,\n",
              "         7.38408208e-01, -1.81452066e-04, -9.94157568e-02,\n",
              "         6.68871582e-01,  4.11802649e-01, -1.75727034e+00,\n",
              "         1.54439771e+00,  1.25197208e+00, -1.03362784e-01,\n",
              "        -3.20987225e-01, -7.27944434e-01, -1.38766539e+00,\n",
              "        -3.74306679e-01,  1.33660853e+00, -2.48256221e-01,\n",
              "        -7.25705087e-01, -5.72073519e-01,  1.14606154e+00,\n",
              "         4.63061035e-01,  4.38823178e-02, -1.15875876e+00,\n",
              "         4.28068340e-01, -5.72173715e-01, -5.15648007e-01,\n",
              "         6.66041076e-01,  7.83595443e-01,  1.11683834e+00,\n",
              "         5.60121000e-01, -5.33320010e-01,  1.15478873e+00,\n",
              "         4.73376870e-01, -1.02029955e+00,  6.77726626e-01,\n",
              "         1.28166473e+00,  1.45307112e+00, -1.26372248e-01,\n",
              "         6.46976531e-01,  6.27514303e-01,  7.50447869e-01,\n",
              "         9.71177459e-01, -2.23002583e-01, -4.92158234e-01,\n",
              "        -1.28040433e+00, -4.17742550e-01, -1.17555106e+00,\n",
              "        -1.50314653e+00, -7.21960366e-01,  1.65591538e+00,\n",
              "        -4.62278068e-01,  1.45662045e+00,  3.08422488e-03,\n",
              "         3.56163830e-01, -4.62251365e-01, -1.25979435e+00,\n",
              "         3.34447056e-01,  5.55101991e-01,  5.95091820e-01,\n",
              "        -9.29278076e-01, -6.67977929e-01, -2.12577194e-01,\n",
              "         1.03374958e+00,  6.50964856e-01,  4.24484432e-01,\n",
              "         1.10474730e+00]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator_image = generator(noise, training=False)"
      ],
      "metadata": {
        "id": "1wR_bl5oxAkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m0fN6HjxAoI",
        "outputId": "a4460698-01a4-4742-ab5f-6a9c28e6cf3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 28, 28, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(generator_image[0, :, :, 0], cmap='gray');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "TBmLp0gv0B8N",
        "outputId": "5a3669c2-00aa-422d-8afb-aa57eb5ab480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAo5klEQVR4nO3de3CV9Z3H8U8SkpMQkgMh5CYhhnATIahcYpRSFIZLtwpCFdTuouPKKKFTpa4Ou1Wr3TEWHWTs4qXrLuhWLLgjMHVdWkAT7ApYgyxySyENApKABnMlN8izfzBkjYLk+5jkl4T3a+bMQPL78Pzy5Dn5cHJOvgnxPM8TAAAdLNT1BgAAlyYKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATPVxv4Ouampp07NgxxcTEKCQkxPV2AABGnuepqqpKKSkpCg298OOcTldAx44dU2pqquttAAC+oyNHjqh///4XfH+nK6CYmBhJ0sMPP6xAINDqXHh4uPlYp06dMmckqaGhwZyJiooyZ2pqaswZP5OVevXqZc5IUlVVlTmTkpLSIcfxc74lf5/b6Ohoc8bP9eons3PnTnNGktLS0swZP/enuro6c6ZPnz7mTEVFhTkjSREREebMt/2P/0L83G/Pfa20Ki0tNWeCwaBpfX19vZYsWXLRPbZbAS1fvlzPPPOMSktLNWrUKP3617/WuHHjLpo79223QCCgyMjIVh/Pz52zqanJnJHk61uDlo/lnNOnT5szfi5kP3uT/H2x9nOsxsbGDjmO5O+Lh5+y66gC8vMFVPJ3/s6cOWPOdNT16qfoJJn+E3xORxWQ32vcz8fk91gX+1rZLi9CWL16tRYtWqTHH39cO3bs0KhRozR16lSdOHGiPQ4HAOiC2qWAli5dqnvvvVd33323hg8frpdeekk9e/bUv//7v7fH4QAAXVCbF1BDQ4MKCgo0efLk/z9IaKgmT56srVu3fmN9fX29KisrW9wAAN1fmxfQF198oTNnzigxMbHF2xMTE8/75Fdubq6CwWDzjVfAAcClwfkPoi5evFgVFRXNtyNHjrjeEgCgA7T5q+Di4+MVFham48ePt3j78ePHlZSU9I31gUDA16syAABdW5s/AoqIiNDo0aO1efPm5rc1NTVp8+bNys7ObuvDAQC6qHb5OaBFixZp3rx5GjNmjMaNG6dly5appqZGd999d3scDgDQBbVLAc2ZM0eff/65HnvsMZWWluqqq67Shg0bvvHCBADApavdJiEsXLhQCxcu9J2vqqoy/aT9tddeaz7G7t27zRlJvoo0LCzMnPHzisCCggJzxs9P2EvS8OHDzRk/0x3Ky8vNmerqanNGkvr27WvO+Lke/HxMX/22dmv97d/+rTkjSaNGjTJnXn75ZXPGz+fJz4iqrKwsc0aSCgsLzRk/E0L8jD7y+9y5n/NnHSJQX1/fqnXOXwUHALg0UUAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMCJdhtG+l316dNHkZGRrV7vZ2hgaKi//q2oqDBnkpOTzRk/vx02MzPTnKmqqjJnJH8DNePj482ZL774wpzp16+fOSP5+5j8iI2NNWfGjx9vznz9F0O21htvvGHOhISEmDPDhg0zZ/wMMC0pKTFnJOnqq682ZxobG82ZTz/91Jz561//as5I0mWXXWbOnDx50rS+tV9beQQEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJzrtNOz6+nrTdF0/U5Y///xzc0aSjh49as74mapbVFRkzlin1kpSbW2tOSNJI0eONGf8TKk+dOiQOZOfn2/OSNKMGTPMmcrKSnNm79695kxZWZk5M2nSJHNGkk6fPm3OjBgxwpzZuXOnOTN48GBzZvv27eaMJP3lL38xZ0aPHm3O1NfXmzN+7n+StG/fPnPGOr29tR8Pj4AAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwIlOO4z0yy+/VCAQaNdjWIadflVoqL23165da87079/fnAkGg+ZMeHi4OSP5G5ZaWFhozlx11VXmTFNTkzkj+RtaOXPmTHMmMzPTnNm4caM588c//tGc8cvP/XXQoEHmzGeffWbOpKenmzOSdPnll5sz77//vjnj5zwcP37cnJH8fZ4qKipM6xlGCgDo1CggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgRKcdRhoTE2MamtezZ0/zMfwOO+3Tp48587//+7++jmXlZ0BoUlKSr2NFRESYM1u2bDFnysrKzJm4uDhzRpKuu+46c6a2ttac2bRpkznzzDPPmDN+BmNK0p49e8yZ6Ohoc+bQoUPmjJ/7n58huJJ0xRVXmDOjR482ZxoaGsyZ/fv3mzOSFBkZac5Yh/u2dj2PgAAATlBAAAAn2ryAfvGLXygkJKTFbdiwYW19GABAF9cuzwFdeeWVLb7H3aNHp32qCQDgSLs0Q48ePXw/sQ0AuDS0y3NABw4cUEpKigYOHKg777xThw8fvuDa+vp6VVZWtrgBALq/Ni+grKwsrVy5Uhs2bNCLL76o4uJife9731NVVdV51+fm5ioYDDbfUlNT23pLAIBOqM0LaPr06br11luVmZmpqVOn6p133lF5ebnWrFlz3vWLFy9WRUVF8+3IkSNtvSUAQCfU7q8O6N27t4YMGaKDBw+e9/2BQMD3D4QCALqudv85oOrqahUVFSk5Obm9DwUA6ELavIAeeugh5efn69ChQ/rggw90yy23KCwsTLfffntbHwoA0IW1+bfgjh49qttvv11lZWXq16+fxo8fr23btqlfv35tfSgAQBcW4nme53oTX1VZWalgMKgnnnjCNDQvJSXFfKwvv/zSnJH0rS8rv5CRI0eaM59//rk5k5aWZs6UlpaaM35lZ2ebM2vXrjVnEhISzBnJ36DGTz75xJzxc736uav6uYYkfwM16+vrzZkbbrjBnNmxY0eHZCQpPT3dnBk7dqw5s27dOnPG74DVcePGmTPWVyefOnVK8+bNU0VFhWJjYy+4jllwAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEu/9COr9qa2tNwxc7cqaqnyGA06dPN2eamprMmZUrV5ozDz30kDkjScXFxeZMfn6+ObN3715zJiMjw5yRpNBQ+//JYmJizJn33nvPnPFzjc+ZM8eckaTPPvvMnPEzYPWee+4xZ2677TZz5sYbbzRnJH/X3tVXX23OLF261Jx54YUXzBlJ+td//VdzZt++fab1dXV1rVrHIyAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA40WmnYYeGhpomE1untUpSaWmpOSNJaWlp5swrr7xizkyaNMmcufbaa82Z6upqc0byNyn40KFD5oyfSca9evUyZyRpy5Yt5sy8efPMmZtvvtmcefbZZ82Zmpoac0aSnnrqKXMmNzfXnHnuuefMmZdfftmcKSoqMmck6Y477jBn/JyHjz/+2Jz58MMPzRlJmjFjhjljvd+eOXOmVet4BAQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATnTaYaS9e/dWVFRUq9cfOXLEfIy4uDhzRpJuv/12c+YPf/iDOeNn2GBKSoo5s2nTJnNGkvbs2WPO/OhHPzJnPv30U3PmnXfeMWckacKECebMW2+9Zc7k5+ebM3fffbc5ExISYs5I0po1a8yZhx56yJypq6szZ2bNmmXOlJSUmDOS1LNnT3MmGAyaM9ddd505Exsba85I0o4dO3zlLOrr61u1jkdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEpx1Gah1SOH78ePMx3n//fXNGkk6ePGnOJCQkmDMRERHmTEZGhjnz5z//2ZyRpKFDh5ozH3zwgTlz5ZVXmjMvvfSSOeM399xzz5kzGzduNGfefPNNcyY6OtqckaTNmzebM1lZWebMuHHjzBk/Q3DDw8PNGUn6z//8T3Pm6NGj5oyfgbvXX3+9OSNJmZmZ5ox1gOnp06dbtY5HQAAAJyggAIAT5gLasmWLbrrpJqWkpCgkJETr1q1r8X7P8/TYY48pOTlZUVFRmjx5sg4cONBW+wUAdBPmAqqpqdGoUaO0fPny875/yZIlev755/XSSy9p+/btio6O1tSpU3394ikAQPdlfhHC9OnTNX369PO+z/M8LVu2TD//+c81Y8YMSdJrr72mxMRErVu3TnPnzv1uuwUAdBtt+hxQcXGxSktLNXny5Oa3BYNBZWVlaevWrefN1NfXq7KyssUNAND9tWkBlZaWSpISExNbvD0xMbH5fV+Xm5urYDDYfEtNTW3LLQEAOinnr4JbvHixKioqmm9HjhxxvSUAQAdo0wJKSkqSJB0/frzF248fP978vq8LBAKKjY1tcQMAdH9tWkDp6elKSkpq8VPUlZWV2r59u7Kzs9vyUACALs78Krjq6modPHiw+e/FxcXauXOn4uLiNGDAAD3wwAP653/+Zw0ePFjp6el69NFHlZKSopkzZ7blvgEAXZy5gD766CPdcMMNzX9ftGiRJGnevHlauXKlHn74YdXU1Gj+/PkqLy/X+PHjtWHDBkVGRrbdrgEAXV6I53me6018VWVlpYLBoJ5++mlTafkZ9tmjh79ZrKtWrTJnrrnmGnMmPT3dnBk0aJA5s2nTJnNGkvbv32/OjB071pypqKgwZ1577TVzRpL+/u//3pw5ceKEOePnxTZ+jvPII4+YM5J8/czesmXLzJkhQ4aYM++9954542dwruRvsOhXv0PUWn6GxvoZwCxJn3zyiTlTWFhoWt/Q0KA1a9aooqLiW5/Xd/4qOADApYkCAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAn/I2D7gDBYFBRUVGtXr9v3z7zMS677DJzRpKSk5PNmffff9+cCQQC5szhw4fNmZMnT5ozkpSZmWnObN++3Zy57bbbzJnnn3/enJGkAwcOmDN+fovvnXfeac4MGDDAnFmwYIE5I0k//elPzZmysjJzxs/1EBISYs7ExMSYM5JUXl5uzoSFhZkzfibz+7mvS9Ktt95qzvz3f/+3aX1dXZ3WrFlz0XU8AgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJzrtMNK//vWvpmGc+/fvNx/Dz3BHSZoyZYo5ExkZac5ERESYM1VVVeZMeHi4OSP5G8I5YcIEc+aRRx4xZx599FFzRpJ69uxpzgSDQXPGz/Dczz//3Jy5+eabzRnJ3+f20KFD5syxY8fMGT/3v7feesuckfwNwi0sLDRnoqOjzZmHH37YnJH8DXO17i80tHWPbXgEBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOdNphpCkpKYqKimr1es/zzMfYtGmTOSNJs2fPNmeuuOIKc6aurs6c8TPAtKioyJyRpKSkJHPm5MmT5sw999xjzkycONGckfxdE2vWrDFnXn75ZXPmhRdeMGf8XuPXXHONOTN48GBzZty4ceaMn+G5N910kzkjSa+++qo5c/XVV5szycnJ5swrr7xizkjSgQMHzJmGhgbT+tZ+7eIREADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA40WmHkX755Zeqra1t9frY2FjzMb7//e+bM5L04YcfmjNhYWHmjJ8Bq36GGpaXl5szkhQdHW3O3HzzzebMz372M3PGz/Ug+fs8/fKXvzRn/AyS9DOEc8GCBeaMJG3fvt2cue2228wZP4NcA4GAObN+/XpzRpKmT59uzgwZMsSc8TNEeOrUqeaMJD355JPmzKFDh0zrWzu8lEdAAAAnKCAAgBPmAtqyZYtuuukmpaSkKCQkROvWrWvx/rvuukshISEtbtOmTWur/QIAuglzAdXU1GjUqFFavnz5BddMmzZNJSUlzbc33njjO20SAND9mF+EMH369Is+MRcIBHz9tkwAwKWjXZ4DysvLU0JCgoYOHar7779fZWVlF1xbX1+vysrKFjcAQPfX5gU0bdo0vfbaa9q8ebN+9atfKT8/X9OnT9eZM2fOuz43N1fBYLD5lpqa2tZbAgB0Qm3+c0Bz585t/vPIkSOVmZmpjIwM5eXladKkSd9Yv3jxYi1atKj575WVlZQQAFwC2v1l2AMHDlR8fLwOHjx43vcHAgHFxsa2uAEAur92L6CjR4+qrKzM10/oAwC6L/O34Kqrq1s8mikuLtbOnTsVFxenuLg4PfHEE5o9e7aSkpJUVFSkhx9+WIMGDfI9NgIA0D2ZC+ijjz7SDTfc0Pz3c8/fzJs3Ty+++KJ27dqlV199VeXl5UpJSdGUKVP0y1/+0tf8JgBA92UuoIkTJ37rkMw//OEP32lD54SGhio0tPXfIayvrzcfo6qqypyRpPj4eHPGz8BPP8M+T506Zc7ceOON5owkvfrqq+aMn+GTM2bMMGd2795tzkjSgQMHzBk/14Of67Wurs6c8fPxSNLVV19tzhQVFZkzpaWl5oyf+9JTTz1lzkjSBx98YM706dPHnPHzMf3Lv/yLOSP5G9Q7cOBA0/rWXqvMggMAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATbf4rudtKTU2NTp8+3er1GRkZ5mMcPXrUnJGk2tpac8bPVN2/+7u/M2eWLVvWIceRpDFjxpgzgwYNMmcKCwvNmczMTHNGkkaPHm3OREVFmTPZ2dnmzNatW82ZW2+91ZyRZJpEf86zzz5rzvzoRz8yZ4YMGWLOlJSUmDOSvynaM2fO7JBMY2OjOSNJAwYMMGfef/990/rWTnvnERAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAONFph5GGhoaaBiL6GQg5ePBgc0aS8vLyzJkbbrjBnPEzfPJXv/qVOeN3KOvcuXPNmQULFpgz11xzjTlTXFxszkjSsGHDzJl9+/aZM34GSf7gBz8wZ9LS0swZSXr55ZfNmZqaGnOmZ8+e5oyf4bR+Pq+SdPfdd5sziYmJ5swf//hHc2bgwIHmjCTFxMSYM9avr6392s0jIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwotMOI42NjVVkZGSr1//Hf/yH+Rg33nijOSNJp06dMmd++9vfmjP/9E//ZM5s27bNnFm7dq05I/kbJDlx4kRzZv/+/ebMD3/4Q3NGkvbu3WvOfPbZZ+aMnyGh8+fPN2d+/OMfmzOSNGbMGHPmyJEj5swrr7xizqSnp5szGRkZ5owkNTU1mTN9+vQxZ3bv3m3OxMfHmzOStHPnTnPGOoD59OnTrVrHIyAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcCLE8zzP9Sa+qrKyUsFgUM8++6yioqJanfMzzG/48OHmjORvmN+4cePMmdBQ+/8PevSwz5c9efKkOSNJx44dM2cSEhLMmQEDBpgzrR2G+HV+zrmfIZzV1dXmzIkTJ8yZyy67zJyRpLlz55ozhw4dMmfeeecdc+bo0aPmTHh4uDkjSTNmzDBn/Hxu/dyXGhoazBnJ3xDTXbt2mdY3NDTo9ddfV0VFhWJjYy+4jkdAAAAnKCAAgBOmAsrNzdXYsWMVExOjhIQEzZw5U4WFhS3W1NXVKScnR3379lWvXr00e/ZsHT9+vE03DQDo+kwFlJ+fr5ycHG3btk0bN25UY2OjpkyZopqamuY1Dz74oH7/+9/rzTffVH5+vo4dO6ZZs2a1+cYBAF2b6RnrDRs2tPj7ypUrlZCQoIKCAk2YMEEVFRX6t3/7N61atar5t42uWLFCV1xxhbZt26Zrr7227XYOAOjSvtNzQBUVFZKkuLg4SVJBQYEaGxs1efLk5jXDhg3TgAEDtHXr1vP+G/X19aqsrGxxAwB0f74LqKmpSQ888ICuv/56jRgxQpJUWlqqiIgI9e7du8XaxMRElZaWnvffyc3NVTAYbL6lpqb63RIAoAvxXUA5OTnavXu3fve7332nDSxevFgVFRXNNz8/UwEA6HrsP7UoaeHChXr77be1ZcsW9e/fv/ntSUlJamhoUHl5eYtHQcePH1dSUtJ5/61AIKBAIOBnGwCALsz0CMjzPC1cuFBr167Vu+++q/T09BbvHz16tMLDw7V58+bmtxUWFurw4cPKzs5umx0DALoF0yOgnJwcrVq1SuvXr1dMTEzz8zrBYFBRUVEKBoO65557tGjRIsXFxSk2NlY/+clPlJ2dzSvgAAAtmAroxRdflCRNnDixxdtXrFihu+66S5L03HPPKTQ0VLNnz1Z9fb2mTp2qF154oU02CwDoPkwF1Jq5pZGRkVq+fLmWL1/ue1PS2YGDlueGkpOTzcewDDv9qpEjR5ozfgY1Xuh5s2/j52Xs9fX15ox09iX2VmlpaebMb37zG3PmlltuMWckNb+i06KxsdGcefLJJ82ZjIwMc2bv3r3mjCTt2LHDnPnqj1+01uWXX27OJCYmmjN79uwxZyQpLCzMnFm9erU54+e+NHToUHNG8ndNDBkyxLS+rq6uVeuYBQcAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnfP1G1I4QDAYVGRnZ6vWWtecUFBSYM5KUmZlpzgwaNMiciY6ONmc+++wzc8bPJHFJSk1NNWfeeecdc2bMmDHmTHV1tTkjSX/+85/NmV27dpkzTz31lDkzduxYc2b37t3mjORvf36mgvfp08ec8XNfHzx4sDkjSWVlZebMHXfcYc785S9/MWeKiorMGUkaPny4OWOdzH/q1KlWreMREADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA40WmHkYaHhys8PLzV6ysqKszHyMjIMGck6fDhw+bMoUOHzJnnnnvOnFmxYoU5U19fb85IUm1trTnz4x//2Jx5+umnzRk/nyPJ38DPkydPmjPr1683ZzzPM2f8DO6UpKVLl5ozM2bMMGfmzp3bIcfp0cPfl7pPPvnEnJk1a5Y5k5eXZ86EhISYM5K0evVqc+bGG280rW/t1xQeAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAEyGenwmH7aiyslLBYFBLly5VVFRUux7rxIkTvnJ79uwxZ/wM7rzqqqvMmS+//NKc2b9/vzkjSZdffrk509DQYM7ceuut5kyvXr3MGUn6zW9+Y86MGjXKnImJiTFnmpqazBm/96Hi4mJzJikpyZyJj483Zz744ANz5tixY+aMJEVHR5szaWlp5syYMWPMmdLSUnNG8vc1IjEx0bS+trZWCxYsUEVFhWJjYy+4jkdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBED9cbuJDTp0/r9OnTrV5fVlZmPka/fv3MGUkaOXKkOXPq1Clzprq62pzxM/R0/Pjx5owkVVRUmDN+Bp8WFBSYM42NjeaMJE2YMMGc8XMdPfnkk+bMjBkzzJkePfzdxQcOHGjO+B34aeVn0Ozf/M3f+DrWa6+9Zs6kpKSYM//1X/9lzvgZBiz5u99aZ1bX1dW1ah2PgAAATlBAAAAnTAWUm5ursWPHKiYmRgkJCZo5c6YKCwtbrJk4caJCQkJa3O6777423TQAoOszFVB+fr5ycnK0bds2bdy4UY2NjZoyZYpqamparLv33ntVUlLSfFuyZEmbbhoA0PWZnqHcsGFDi7+vXLlSCQkJKigoaPHkbc+ePX39dkQAwKXjOz0HdO7VFHFxcS3e/vrrrys+Pl4jRozQ4sWLv/UVYPX19aqsrGxxAwB0f75fht3U1KQHHnhA119/vUaMGNH89jvuuENpaWlKSUnRrl279Mgjj6iwsFBvvfXWef+d3NxcPfHEE363AQDoonwXUE5Ojnbv3q0//elPLd4+f/785j+PHDlSycnJmjRpkoqKipSRkfGNf2fx4sVatGhR898rKyuVmprqd1sAgC7CVwEtXLhQb7/9trZs2aL+/ft/69qsrCxJ0sGDB89bQIFAQIFAwM82AABdmKmAPM/TT37yE61du1Z5eXlKT0+/aGbnzp2SpOTkZF8bBAB0T6YCysnJ0apVq7R+/XrFxMSotLRUkhQMBhUVFaWioiKtWrVKP/jBD9S3b1/t2rVLDz74oCZMmKDMzMx2+QAAAF2TqYBefPFFSWd/2PSrVqxYobvuuksRERHatGmTli1bppqaGqWmpmr27Nn6+c9/3mYbBgB0D+ZvwX2b1NRU5efnf6cNAQAuDZ12GnZjY6PCwsJM661KSkrMGUnq27evOePnW5Bvv/22OXPVVVeZMydPnjRnJGnIkCHmjJ+Jzlu2bDFnYmNjzRlJKi8vN2d27NhhzviZzvzVH3doraqqKnNG6rjJ1lFRUebMsGHD2mEn5/fDH/7QnPHztWjw4MHmjN/PbUxMjDkTHx9vWt/a6f8MIwUAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJzrtMNKysjLTb0rt2bOn+RitHZj3dbt27TJnhg8fbs605hf+fZ2foafPPPOMOSNJ1113nTmzevVqc2b06NHmzMGDB80ZSYqLizNn/AynHTNmjDnjZ9J8dna2OSNJp0+fNmdCQ+3/n/XzeZozZ44589vf/tackfwN3N2zZ48507t3b3PG78Dduro6c8b6Na++vr5V63gEBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnOh0s+A8z5PU+llC5/iZQ2U9xjkNDQ3mTE1NjTnjZ2aTn+M0NjaaM5K//fk5d7W1teaM38+tn4/Jz7H8zCHsqOP4PVZISEiHHKe6urpDjiN13LXn5zhNTU3mjNQx1/i59ee+nl9IiHexFR3s6NGjSk1Ndb0NAMB3dOTIEfXv3/+C7+90BdTU1KRjx44pJibmG/+jqqysVGpqqo4cOeJ7Emx3wHk4i/NwFufhLM7DWZ3hPHiep6qqKqWkpHzrd6c63bfgQkNDv7UxpbNjyC/lC+wczsNZnIezOA9ncR7Ocn0egsHgRdfwIgQAgBMUEADAiS5VQIFAQI8//rjpN6V2R5yHszgPZ3EezuI8nNWVzkOnexECAODS0KUeAQEAug8KCADgBAUEAHCCAgIAONFlCmj58uW6/PLLFRkZqaysLH344Yeut9ThfvGLXygkJKTFbdiwYa631e62bNmim266SSkpKQoJCdG6detavN/zPD322GNKTk5WVFSUJk+erAMHDrjZbDu62Hm46667vnF9TJs2zc1m20lubq7Gjh2rmJgYJSQkaObMmSosLGyxpq6uTjk5Oerbt6969eql2bNn6/jx44523D5acx4mTpz4jevhvvvuc7Tj8+sSBbR69WotWrRIjz/+uHbs2KFRo0Zp6tSpOnHihOutdbgrr7xSJSUlzbc//elPrrfU7mpqajRq1CgtX778vO9fsmSJnn/+eb300kvavn27oqOjNXXqVF9DFzuzi50HSZo2bVqL6+ONN97owB22v/z8fOXk5Gjbtm3auHGjGhsbNWXKlBZDeB988EH9/ve/15tvvqn8/HwdO3ZMs2bNcrjrttea8yBJ9957b4vrYcmSJY52fAFeFzBu3DgvJyen+e9nzpzxUlJSvNzcXIe76niPP/64N2rUKNfbcEqSt3bt2ua/NzU1eUlJSd4zzzzT/Lby8nIvEAh4b7zxhoMddoyvnwfP87x58+Z5M2bMcLIfV06cOOFJ8vLz8z3PO/u5Dw8P9958883mNfv27fMkeVu3bnW1zXb39fPgeZ73/e9/3/vpT3/qblOt0OkfATU0NKigoECTJ09ufltoaKgmT56srVu3OtyZGwcOHFBKSooGDhyoO++8U4cPH3a9JaeKi4tVWlra4voIBoPKysq6JK+PvLw8JSQkaOjQobr//vtVVlbmekvtqqKiQpIUFxcnSSooKFBjY2OL62HYsGEaMGBAt74evn4eznn99dcVHx+vESNGaPHixb5/PUd76XTDSL/uiy++0JkzZ5SYmNji7YmJidq/f7+jXbmRlZWllStXaujQoSopKdETTzyh733ve9q9e7diYmJcb8+J0tJSSTrv9XHufZeKadOmadasWUpPT1dRUZH+8R//UdOnT9fWrVsVFhbmenttrqmpSQ888ICuv/56jRgxQtLZ6yEiIkK9e/dusbY7Xw/nOw+SdMcddygtLU0pKSnatWuXHnnkERUWFuqtt95yuNuWOn0B4f9Nnz69+c+ZmZnKyspSWlqa1qxZo3vuucfhztAZzJ07t/nPI0eOVGZmpjIyMpSXl6dJkyY53Fn7yMnJ0e7duy+J50G/zYXOw/z585v/PHLkSCUnJ2vSpEkqKipSRkZGR2/zvDr9t+Di4+MVFhb2jVexHD9+XElJSY521Tn07t1bQ4YM0cGDB11vxZlz1wDXxzcNHDhQ8fHx3fL6WLhwod5++2299957LX59S1JSkhoaGlReXt5ifXe9Hi50Hs4nKytLkjrV9dDpCygiIkKjR4/W5s2bm9/W1NSkzZs3Kzs72+HO3KuurlZRUZGSk5Ndb8WZ9PR0JSUltbg+KisrtX379kv++jh69KjKysq61fXheZ4WLlyotWvX6t1331V6enqL948ePVrh4eEtrofCwkIdPny4W10PFzsP57Nz505J6lzXg+tXQbTG7373Oy8QCHgrV6709u7d682fP9/r3bu3V1pa6nprHepnP/uZl5eX5xUXF3v/8z//402ePNmLj4/3Tpw44Xpr7aqqqsr7+OOPvY8//tiT5C1dutT7+OOPvU8//dTzPM97+umnvd69e3vr16/3du3a5c2YMcNLT0/3amtrHe+8bX3beaiqqvIeeughb+vWrV5xcbG3adMm75prrvEGDx7s1dXVud56m7n//vu9YDDo5eXleSUlJc23U6dONa+57777vAEDBnjvvvuu99FHH3nZ2dledna2w123vYudh4MHD3pPPvmk99FHH3nFxcXe+vXrvYEDB3oTJkxwvPOWukQBeZ7n/frXv/YGDBjgRUREeOPGjfO2bdvmeksdbs6cOV5ycrIXERHhXXbZZd6cOXO8gwcPut5Wu3vvvfc8Sd+4zZs3z/O8sy/FfvTRR73ExEQvEAh4kyZN8goLC91uuh1823k4deqUN2XKFK9fv35eeHi4l5aW5t17773d7j9p5/v4JXkrVqxoXlNbW+stWLDA69Onj9ezZ0/vlltu8UpKStxtuh1c7DwcPnzYmzBhghcXF+cFAgFv0KBB3j/8wz94FRUVbjf+Nfw6BgCAE53+OSAAQPdEAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACf+D/u/CbHDa2IxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Discriminator"
      ],
      "metadata": {
        "id": "DlFUJIpZ0kTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout: https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
        "\n",
        "Conv2d x Conv2dTranspose: https://stackoverflow.com/questions/68976745/in-keras-what-is-the-difference-between-conv2dtranspose-and-conv2d"
      ],
      "metadata": {
        "id": "C2ufz1fd0uZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "  network = tf.keras.Sequential()\n",
        "\n",
        "  #14X14X64\n",
        "  network.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "  network.add(layers.LeakyReLU())\n",
        "  network.add(layers.Dropout(0.3))\n",
        "\n",
        "  #7X7X128\n",
        "  network.add(layers.Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "  network.add(layers.LeakyReLU())\n",
        "  network.add(layers.Dropout(0.3))\n",
        "\n",
        "  network.add(layers.Flatten())\n",
        "  network.add(layers.Dense(1))\n",
        "\n",
        "  network.summary()\n",
        "\n",
        "  return network\n"
      ],
      "metadata": {
        "id": "AHI_kZeO0B-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahk-gnQd0CBP",
        "outputId": "60c6747c-e4f3-41db-d09d-4ac1ca303085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " 7 * 7 * 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1onAK5Zz3Hpj",
        "outputId": "dd1706eb-9a96-4080-93e8-633842e189d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6272"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzVdkuSr0CE6",
        "outputId": "b96a41a6-06d1-424f-d290-38ddda884f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 28, 28, 1) dtype=float32 (created by layer 'conv2d_input')>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator(generator_image, training =False) #logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6bNdizY3S89",
        "outputId": "cd01f2c3-f523-43c0-acad-e4869ab85801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.00086714]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.sigmoid(0.00205972)        # pass the above values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_rO74XN3S_P",
        "outputId": "d2115b5d-e62b-4d10-a8dc-a4c18e99b9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5005149>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error calculation"
      ],
      "metadata": {
        "id": "Jf0cMjsb4BUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logits: https://deepai.org/machine-learning-glossary-and-terms/logit"
      ],
      "metadata": {
        "id": "BEQhY_ky4KrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method quantifies how well the discriminator is able to distinguish real images from fakes images. It compares the discriminator predictions on real images with an array of 1s and the discriminator predictions on fake (generated) images withanarrayof0s"
      ],
      "metadata": {
        "id": "T26RLhRorUIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "I8DKVNtG3TBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.ones_like(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ofKNKQXtBPJ",
        "outputId": "602fed5e-fc3a-4f70-b245-76129875353c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(expected_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(expected_output), expected_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "DRambOIotBkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "HuZraKi1tBxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001)"
      ],
      "metadata": {
        "id": "hBjYjTwotB8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the GAN and Visualizing the results"
      ],
      "metadata": {
        "id": "RizzGREs0KTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on: https://www.tensorflow.org/beta/tutorials/generative/dcgan\n",
        "\n",
        "@tf.function: https://www.tensorflow.org/guide/function#:~:text=You%20can%20use%20tf.,is%20required%20to%20use%20SavedModel%20."
      ],
      "metadata": {
        "id": "CvhgHOHC0Q7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBojLO-ytCJh",
        "outputId": "eb804e7c-1632-452e-b2ce-9a80433bcffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "noise_dimension = 100\n",
        "nummber_of_images = 16"
      ],
      "metadata": {
        "id": "_D4oQ_oJ3TDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size,noise_dimension"
      ],
      "metadata": {
        "id": "RAkiyhFO3TFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09476ade-f288-4ae7-b668-a634b3665be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "#This decorator tells TensorFlow to compile the fonction into a graph,\n",
        "#which improves performance by optimizing the execution,\n",
        "#especially on large datasets on when training over many iterations.\n",
        "def train(images):\n",
        "        noise = tf.random.normal([batch_size, noise_dimension])\n",
        "        #print(noise.shape)\n",
        "\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "          # tf.GradientTape(): TensorFlow's GradientTape is used to record operations s\n",
        "          # for automatic differentiation. In this case, two tapes are used to\n",
        "          # separately track the computations for the generator (gen_tape)\n",
        "          # and discriminator (disc_tape).\n",
        "          # This is crucial because both networks need to be trained simultaneously but independently.\n",
        "          generated_images= generator(noise, training=True)\n",
        "\n",
        "          expected_output = discriminator(images, training=True)\n",
        "          fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "          gen_loss = generator_loss(fake_output)\n",
        "          disc_loss = discriminator_loss(expected_output, fake_output)\n",
        "\n",
        "          # generator(noise, training-True): The generator takes the random noise\n",
        "          # as input and produces generated_images. The training True flag ensures\n",
        "          # that any training-specific behavior (like dropout) is activated.\n",
        "\n",
        "\n",
        "          # discriminator(images, training=True): The discriminator takes the real images\n",
        "          # from the dataset and produces expected_output, which is its prediction\n",
        "          # about the realness of the images.\n",
        "\n",
        "          # discriminator(generated_images, training=True): The discriminator also\n",
        "          # evaluates the generated images produred by the generator and outputs\n",
        "          # fake_output, which is its prediction about the realness of the fake images.\n",
        "\n",
        "          generato_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "          discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "          # gen_tape.gradient: Computes the gradients of the gen_loss with respect to\n",
        "          # the generator's trainable variables (its weights and biases).\n",
        "          # These gradients will be used to update the generator.\n",
        "\n",
        "          # disc_tape.gradient: Computes the gradients of the disc_loss with respect\n",
        "          # to the discriminator's trainable variables.\n",
        "          # These gradients will be used to update the discriminator.\n",
        "\n",
        "          generator_optimizer.apply_gradients(zip(generato_gradients, generator.trainable_variables))\n",
        "          discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
        "          # generator_optimizer.apply_gradients: This applies the computed gradients\n",
        "          # to update the generator's parameters, using the generator_optimizer.\n",
        "          # The zip(generator_gradients, generator.trainable_variables) pairs each gradient\n",
        "          #with the corresponding trainable variable.\n",
        "\n",
        "\n",
        "          #discriminator_optimizer.apply_gradients: Similarly, this updates the discriminator"
      ],
      "metadata": {
        "id": "1Rdqm9xy3TIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "noise_dimension = 100\n",
        "nummber_of_images = 16"
      ],
      "metadata": {
        "id": "BqDpLYHh5aaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size,noise_dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuHHe_F45aex",
        "outputId": "84effa57-7e7e-4ad8-d5e3-ae198c8ad1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images=tf.random.normal([nummber_of_images, noise_dimension])\n",
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nR7JMTd5aiJ",
        "outputId": "81c8bdd6-103e-4e61-824b-86afb35b2335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "X_train_batch= X_train.as_numpy_iterator().next()\n",
        "train(X_train_batch)\n",
        "\n",
        "# Purpose : this line configures Tensorflow to run functions eagerly.\n",
        "# even if they are decorated with @tf.function.\n",
        "# What is Eager Execution?: In eager execution, TensorFlow operations are\n",
        "#executed inmediately as Python operations (like normal Python code) (x)\n",
        "# Werather than being compiled into a graph. This is helpful for debugging\n",
        "#because it allows you to step through operations and inspect #intermediate values.\n",
        "#why use run functions_eagerly (True)?: By default,\n",
        "#TensorFlow compiles @tf.function decorated code into a graph for efficiency.\n",
        "#However, if you need to debug your training process or check intermediate\n",
        "#results (like inspecting gradients, losses, etc.), you can enable seager execution.\n",
        "#This makes TensorFlow behave more like regular Python code #and simplifies debugging."
      ],
      "metadata": {
        "id": "BWkRI1qE5vdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images=tf.random.normal([nummber_of_images, noise_dimension])\n",
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfbDiuWt8Dz9",
        "outputId": "adb12b19-f11c-4b1d-d8e7-3ddec9223f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(dataset, epochs, test_images):\n",
        "  for epoch in range(epochs):\n",
        "    #print(epoch)\n",
        "    for image_batch in dataset:\n",
        "      #print(image_batch.shape)\n",
        "      train(image_batch)"
      ],
      "metadata": {
        "id": "Jg_7yJEr5vfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gan(X_train, epochs, test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "VrB6KJQE5viV",
        "outputId": "eac55c5d-0a84-400a-f276-d7c9a72efe8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-842f45cbf026>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-b7c8802e8045>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(dataset, epochs, test_images)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m#print(image_batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_functions_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[0;31m# Only count the statistics the first time, before initialization took\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-768f181d7e31>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0mgenerato_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m           \u001b[0mdiscriminator_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m           \u001b[0;31m# gen_tape.gradient: Computes the gradients of the gen_loss with respect to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0;31m# the generator's trainable variables (its weights and biases).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   return [\n\u001b[0;32m--> 582\u001b[0;31m       gen_nn_ops.conv2d_backprop_input(\n\u001b[0m\u001b[1;32m    583\u001b[0m           \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1617\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1620\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Conv2DBackpropInput\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**dataset**: The input dataset used for training, typically a set of images,\n",
        "\n",
        "**epochs**: The number of training iterations (how many times the model should go through the dataset),\n",
        "\n",
        "**test images**: A set of test images used to generate output during the training process for visualizing the progress. Inside the epoch loop, another loop runs through each image_batch in the dataset.\n",
        "\n",
        "**train(image batch):** This is a placeholder for the training function that handles training the GAN. After every epoch, it prints the current epoch number.\n",
        "\n",
        "**generator(test_images, training=False):** This calls the generator model with test images to generate new images. The argument training-False indicates that the generator is in inference mode, so it won't apply training-related operations like dropout.\n",
        "\n",
        "**fig = plt.figure(figsize=(10,10))**: Creates a figure for"
      ],
      "metadata": {
        "id": "TkTc-YcS968d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(dataset, epochs, test_images):\n",
        "  for epoch in range(epochs):\n",
        "    #print(epoch)\n",
        "    for image_batch in dataset:\n",
        "      #print(image_batch.shape)\n",
        "      train(image_batch)\n",
        "\n",
        "      print('Epoch:',epoch + 1)\n",
        "      generator_image = generator(test_images, training=False)\n",
        "      fig=plt.figure(figsize=(10,10))\n",
        "      for i in range(generator_image.shape[0]):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow(generator_image[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "od72Pk_O5vlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jf_S9i4O5voo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}